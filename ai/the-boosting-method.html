<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Boosting Method - Spirits Away</title>
    <link rel="shortcut icon" type="image/x-icon" href="\favicon.ico">
    <link rel="stylesheet" href="http://spiritsaway.info/theme/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="http://spiritsaway.info/theme/font-awesome/css/font-awesome.min.css" type="text/css" />
    <link rel="stylesheet" href="http://spiritsaway.info/theme/css/niu2.css" type="text/css" />

    <link rel="canonical" href="http://spiritsaway.info/ai/the-boosting-method.html" />
    
    <script type="text/javascript">window.onload=function(){};</script>
    <!--[if lt IE 9]>
        <script src="http://spiritsaway.info/theme/js/html5shiv.js"></script>
        <script src="http://spiritsaway.info/theme/js/respond.min.js"></script>
    <![endif]-->
  </head>
  <body> 
    <div id="body-header">
<div class="navbar navbar-inverse navbar-fixed-top">
<div class="col-md-12">
    <div class="navbar-header col-md-offset-2">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="http://spiritsaway.info">
            <i class="fa fa-home"></i>Spirits Away
        </a>
    </div>
    <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
        <ul class="nav navbar-nav">
            <li><a href="/about.html" title="about">
                <i class="fa fa-anchor"></i>关于</a>
            </li>
            <li><a href="/archives.html" title="archives">
                <i class="fa fa-archive"></i>存档</a>
            </li>
            <li><a href="/tag/" title="tags">
                <i class="fa fa-tag"></i>标签</a>
            </li>
        <!-- category dropdown list -->
        <li class="dropdown">
           <a href="#" class="dropdown-toggle" data-toggle="dropdown">
                <i class="fa fa-folder-open"></i>分类<b class="caret"></b>
           </a>
           <ul class="dropdown-menu">
               <li><a href="http://spiritsaway.info/ai/index.html">
                   <i class="fa fa-folder-close"></i>AI
                      (3)</a></li>
               <li><a href="http://spiritsaway.info/algorithm/index.html">
                   <i class="fa fa-folder-close"></i>Algorithm
                      (2)</a></li>
               <li><a href="http://spiritsaway.info/code/index.html">
                   <i class="fa fa-folder-close"></i>Code
                      (3)</a></li>
               <li><a href="http://spiritsaway.info/cpp/index.html">
                   <i class="fa fa-folder-close"></i>CPP
                      (4)</a></li>
               <li><a href="http://spiritsaway.info/math/index.html">
                   <i class="fa fa-folder-close"></i>Math
                      (4)</a></li>
           </ul>
        </li>
        <!--  self defined dropdown list -->
        </ul>
        
        <!-- right nav bar -->
        <ul class="nav navbar-nav navbar-right">
        <!-- google custom search -->
       </ul>
    </nav>
</div>
</div>    </div>
    
    <div id="body-content">
<div class="col-md-8 col-md-offset-2">
    <h1 id="content-heading">The Boosting Method</h1>
</div>
<div id="niu2-left-container" class="col-md-6 col-md-offset-2 with-right-border">
    <div id="niu2-main-content">
        <h1 id="2c97b8">Boosting方法</h1>
<p>Boosting方法是一种组合方法，处理的是分类问题（当前对于分类的讨论限制为二分类，下面则不再复述）。其中心思想相当的简单：每次利用一个弱分类器(weak learner)对数据进行分类，每次分类完成之后，将分错的数据权重提高一点，并迭代进行多次分类。最后通过综合多次分类的结果作为最终的分类器，这样最终得到的分类器在测试数据与训练数据上都可以得到比较好的成绩。</p>
<h1 id="e98c41">boosting简单图解</h1>
<p>boosting的大概流程如下图：<br />
<img alt="boosting概述" src="http://spiritsaway.info/ai/image/BOOSTING/boosting_procedure.png" /></p>
<p>训练集中一共有n个点，我们可以为里面的每一个点赋上一个权重<span class="math">\(W_i(0 \le i &lt; n)\)</span>，表示这个点的重要程度，初始时都相等（都赋值为1就可以了）。通过依次训练模型的过程，我们对点的权重进行修正，如果分类正确了，权重不变或者降低；如果分类错了，则权重提高。程序越往后执行，训练出的模型就越会在意那些容易分错（权重高）的点。正因为boosting对于错误分类的过于强调，在数据有错误或误差时如果使用强分类器来做基础分类器的话会导致非常严重的overfitting。因此，boosting中推荐使用弱分类器（必须大于1/2）来进行组装。</p>
<p>上图中绿色的线就是表示依次训练模型。当全部的程序执行完后，会得到M个模型，分别对应上图的<span class="math">\(y_1\cdots y_M(x)\)</span>，通过加权的方式组合成一个最终的模型<span class="math">\(Y_M(x)\)</span>。</p>
<p><img alt="PRML boosting" src="http://spiritsaway.info/ai/image/BOOSTING/prml_boosting_illustration.png" /></p>
<p>上图（图片来自prml p660）就是一个Boosting的分类过程，绿色的线表示目前取得的模型（模型是由前m次得到的模型合并得到的），虚线表示当前这次模型。每次分类的时候，会更关注分错的数据，上图中，红色和蓝色的点就是数据，点越大表示权重越高，看看右下角的图片，当m=150的时候，获取的模型已经几乎能够将红色和蓝色的点区分开了。</p>
<p>当前只是一个浅显的介绍，并没有涉及那些具体细节：对于点的权重如何调整，对于生成的多个分类器如何组合，如何选择和使用弱分类器。此外，还有最重要的一点：该方法为何能得到非常好的效果。下面便以几种知名的boosting方法来解释其中的一些细节和原理。</p>
<h1 id="085c16">极简boosting</h1>
<p>话说这种方式的boosting我还不知道它的正式学名。。。这种boosting包含了一下几个部分：</p>
<ul>
<li>
<p>弱分类器：对于<span class="math">\(n\)</span>个权值分别为<span class="math">\(\{w_1,w_2,\cdots,w_n\}\)</span>的数据<span class="math">\(\{a_1,a_2,\cdots,a_n\}\)</span>，该分类器所能正确分类的数据的权值总和至少为<span class="math">\((\frac{1}{2}+\gamma)\sum_{i=1}^{n}{w_i}\)</span>，其中<span class="math">\(\gamma\)</span>非负。</p>
</li>
<li>
<p>权重更新：每次分类之后，对于错分数据的权重乘以<span class="math">\(1+\epsilon\)</span>(<span class="math">\(\epsilon\)</span>大于0)，其他的不变。</p>
</li>
<li>
<p>投票分类：最终数据的分类标签由所有的分类器投票决定，每个分类器的投票权重相等，即majority vote。</p>
</li>
</ul>
<p>现在我们来证明一下这个boosting是有效的：随着分类的次数<span class="math">\(T\)</span>的增加，数据错误分类的个数<span class="math">\(m\)</span>会逐渐趋近于0.</p>
<p>首先，考虑到分类器的组合是majority vote 方式。如果一个数据被错误分类了，则该数据在所有的分类器中至少分类错误了<span class="math">\(T/2\)</span>次。又由于每次错误分类都会导致权值放大<span class="math">\(1+\epsilon\)</span>。因此，被误分类的数据最后的权重值至少为<span class="math">\((1+\epsilon)^{T/2}\)</span>。所以，总的来说，这<span class="math">\(m\)</span>个错误分类数据的权值总和至少为<span class="math">\(m(1+\epsilon)^{T/2}\)</span>。</p>
<p>现在我们来考虑最后一次分类时的所有数据的权重和。每次分类时，一个数据被误分类的概率最多为<span class="math">\(f=1/2-\gamma\)</span>，被正确分类的概率至少为<span class="math">\(1/2+\gamma\)</span>。又由于每一个数据被分类之间是独立事件，用<span class="math">\(weight(t)\)</span>代表第<span class="math">\(t\)</span>次分类并调整权重之后的所有数据的权重总和，则我们有下式：</p>
<div class="math">\begin{equation}\begin{split}weight(t+1)&amp;\le((1+\epsilon)f+1-f)\times weight(t)\\&amp;=(1+\epsilon f)\times weight(t)\\&amp;\le(1+\frac{\epsilon}{2}-\gamma\epsilon)\times weight(t)\end{split}\end{equation}</div>
<p><br />
又由于初始时<span class="math">\(w(0)=n\)</span>，所以：</p>
<div class="math">\begin{equation}weight(T)\le n(1+\frac{\epsilon}{2}-\gamma\epsilon)^T\end{equation}</div>
<p><br />
同时被误分类的数据的权重的总和不可能大于所有数据权重的总和，因此我们有下式：</p>
<div class="math">\begin{equation}m(1+\epsilon)^{T/2}\leq n(1+\frac{\epsilon}{2}-\gamma\epsilon)^T\end{equation}</div>
<p><br />
对于上士取对数，可以得到如下结果：</p>
<div class="math">\begin{equation}ln(m)+\frac{T}{2}ln(1+\epsilon)\le ln(n)+Tln(1+\frac{\epsilon}{2}-\gamma\epsilon)\end{equation}</div>
<p><br />
同时，利用自然对数的近似<span class="math">\(ln(1+\delta)=\delta\)</span>，我们可以化简为：</p>
<div class="math">\begin{equation}ln(m)\le ln(n)-T\gamma\epsilon\end{equation}</div>
<p><br />
所以，错误分类数是指数衰减的。当<span class="math">\(T=(1+ln(n))/{\gamma\epsilon}\)</span>时，<span class="math">\(m\le \frac{1}{e}\)</span>，即不存在误分类。</p>
<p>因此，分类次数只需要<span class="math">\(O(log(n))\)</span>就可以达到完美分类。</p>
<h1 id="3437d4">adaboost</h1>
<p>adaboost相对于上面的极简boost方法，做了一些修改。数据采取的是二元组形式<span class="math">\(\{x_i,y_i\}\)</span>，其中<span class="math">\(y_i\)</span>为<span class="math">\(\{+1,-1\}\)</span>。设<span class="math">\(G_m\)</span>为第<span class="math">\(m\)</span>个分类器，<span class="math">\(e_m\)</span>为第<span class="math">\(m\)</span>次分类时的分类错误率，<span class="math">\(w_{m,i}\)</span>为第<span class="math">\(m\)</span>轮分类之前数据<span class="math">\(\{x_i,y_i\}\)</span>的权重，同时保存一个变量<span class="math">\(a_m\)</span>：</p>
<div class="math">\begin{equation}a_m=\frac{1}{2}log(\frac{1-e_m}{e_m})\end{equation}</div>
<ul>
<li>
<p>初始权重为<span class="math">\(\frac{1}{n}\)</span>；</p>
</li>
<li>
<p>权重更新策略不同，对于分类正确的样本会权值减少为原来的<span class="math">\(e^{-a_m}/Z_m\)</span>，对分类错误的样本权值会增加为原来的<span class="math">\(e^{a_m}/Z_m\)</span>。这里的<span class="math">\(Z_m\)</span>是一个规范化因子，其值为<div class="math">$$Z_m=\sum_{i=1}^{n}{w_{m,i}\text{exp}(-a_my_iG_m(x_i))}$$</div>
</p>
</li>
<li>
<p>最终分类器不再是简单的majority vote ，而是带权重的majority vote。每个分类器<span class="math">\(G_m\)</span>的权重为<span class="math">\(a_m\)</span>。</p>
</li>
</ul>
<p>最终的分类器<span class="math">\(G(x)\)</span>为</p>
<div class="math">\begin{equation}G(x)=sgn(\sum_{m=1}^{M}{a_mG_m(x)})\end{equation}</div>
<p>现在，我们来证明该方法的有效性。首先给出adaboost方法训练误差的上界：</p>
<div class="math">\begin{equation}\frac{1}{n}\sum_{i=1}^{n}{I(G(x_i)\ne y_i)}\le \frac{1}{n}\sum_{i=1}^{n}{e^{-y_if(x_i)}}=\prod_{j=0}^{m}{Z_m}\end{equation}</div>
<p><br />
下面，我们对该误差上界来进行证明。上式的左边很容易证明：</p>
<div class="math">\begin{equation}G(x_i)\ne y_i \Rightarrow f(x_i)y_i&lt;0\Rightarrow 1&lt;e^{-f(x_i)y_i}\end{equation}</div>
<p><br />
难点是后半部分，这里我们首先给出adaboost中<span class="math">\(Z_m\)</span>与<span class="math">\(w_{m+1,i}\)</span>之间的关系：</p>
<div class="math">\begin{equation}\begin{split}w_{m+1,i}&amp;=\frac{w_{m,i}}{Z_m}\text{exp}(-a_my_iG_m(x_i))\\Z_mw_{m+1,i}&amp;=w_{m,i}\text{exp}(-a_my_iG_m(x_i))\end{split}\end{equation}</div>
<p><br />
接下来，开始展开右边的等式的推导过程：</p>
<div class="math">\begin{equation}\begin{split}\frac{1}{n}\text{exp}(-y_if(x_i))&amp;=\frac{1}{n}\sum_{i}\text{exp}(-\sum_{m=1}^{M}{a_my_iG_m(x_i)})\\&amp;=\sum_{i}{w_{1,i}\text{exp}(-\sum_{m=1}^{M}{a_my_iG_m(x_i)})}\\&amp;=\sum_{i}{w_{1,i}\prod_{m=1}^{M}{\text{exp}(-{a_my_iG_m(x_i)})}}\\&amp;=Z_1\sum_{i}{w_{2,i}\prod_{m=2}^{M}{\text{exp}(-{a_my_iG_m(x_i)})}}\\&amp;=Z_1Z_2\sum_{i}{w_{3,i}\prod_{m=3}^{M}{\text{exp}(-{a_my_iG_m(x_i)})}}\\&amp;=Z_1Z_2\cdots Z_{M-1}\sum_{i}{w_{M,i}{\text{exp}(-{a_My_iG_M(x_i)})}}\\&amp;=\prod_{m=1}^{M}{Z_m}\end{split}\end{equation}</div>
<p>由这个误差公式可以看出，每次做弱分类的时候，如果把本次分类的<span class="math">\(Z_m\)</span>控制的尽可能的小，则总体的训练误差也会随之减小。总的来说，这是一个贪心的过程。</p>
<p>虽说我们已经把这个误差上界求出来了，但是该上界的上界这里并没有体现。所以，我们继续求上界的上界。前人给出了如下结论：</p>
<div class="math">\begin{equation}\prod_{m=1}^{M}{Z_m}=\prod_{m=1}^{M}{(2\sqrt{e_m(1-e_m)})}=\prod_{m=1}^{M}{\sqrt{1-4{{\gamma}_m}^2}}\leq \text{exp}(-2\sum_{m=1}^{M}{\gamma_m}^2)\end{equation}</div>
<p><br />
其中，<span class="math">\(\gamma_m=1/2-e_m\)</span>。</p>
<p>下面开始证明这个结论：</p>
<div class="math">\begin{equation}\begin{split}Z_m&amp;=\sum_{i=1}^{n}{w_{m,i}\text{exp}(a_my_iG_m(x_i))}\\&amp;=\sum_{y_i=G_m(x_i)}{w_{m,i}e^{-a_m}}+\sum_{u_i\ne G_m(x_i)}{w_{m,i}e^{a_m}}\\&amp;=(1-e_m)e^{-a_m}+e_me^{a_m}\\&amp;=2\sqrt{e_m(1-e_m)}\\&amp;=\sqrt{1-4\gamma_m^2}\end{split}\end{equation}</div>
<p><br />
又由于<span class="math">\(\sqrt{1-4a}\le 1-2a\le e^{-2a}\)</span>，所以</p>
<div class="math">\begin{equation}\prod_{m=1}^{M}(\sqrt{1-4\gamma_m^2})\le \text{exp}(-2\sum_{m=1}^{M}{\gamma_m^2})\end{equation}</div>
<p><br />
取<span class="math">\(\gamma_1,\gamma_2,\cdots,\)</span>中的最小值为<span class="math">\(\gamma\)</span>，并将这些不等式串接起来，可以得到</p>
<div class="math">\begin{equation}\frac{1}{n}\sum_{i=1}^{N}{I(G(x_i)\ne y_i)}\le \text{exp}(-2M\gamma^2)\end{equation}</div>
<p><br />
所以，误差是指数衰减的，与之前的的极简boosting类似。</p>
<p>本来还要深入一下讨论gradient boost的，考虑到篇幅，还是以后再写吧。</p>
<h1 id="ea6f3b">参考链接</h1>
<ul>
<li>
<p>prml上关于boosting的部分：<a href="http://book.douban.com/subject/2061116/">http://book.douban.com/subject/2061116/</a></p>
</li>
<li>
<p>csdn博主july写的adaboost：<a href="http://blog.csdn.net/v_july_v/article/details/40718799">http://blog.csdn.net/v_july_v/article/details/40718799</a></p>
</li>
<li>
<p>hopcroft的新作 fundations of data science：<a href="http://research.microsoft.com/en-US/people/kannan/book-no-solutions-aug-21-2014.pdf">http://research.microsoft.com/en-US/people/kannan/book-no-solutions-aug-21-2014.pdf</a></p>
</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>
    <div id="content-comments">
<div id="disqus_thread"></div>
<script type="text/javascript">var disqus_shortname="SpiritsAway";(function(){var a=document.createElement("script");a.type="text/javascript";a.async=true;a.src="//"+disqus_shortname+".disqus.com/embed.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)})();</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

</div>
<div class="niu2-right-container col-md-2">
    <div id="niu2-sidebar-meta" class="niu2-sidebar">
        <div class="niu2-sidebar-label"><i class="fa fa-calendar"></i>发布时间:</div>
        <div class="niu2-sidebar-value">2015-04-17</div>
        <div class="niu2-sidebar-label"><i class="fa fa-open-folder"></i>分类:</div>
        <div class="niu2-sidebar-value"><a href="http://spiritsaway.info/ai/index.html">AI</a></div>
        <div class="niu2-sidebar-label"><i class="fa fa-tag"></i>标签:</div>
 
            <div class="niu2-sidebar-inter-value niu2-sidebar-tag"><a href="http://spiritsaway.info/tag/boosting.html">Boosting</a><sup>1</sup></div>
            <div class="niu2-sidebar-inter-value niu2-sidebar-tag"><a href="http://spiritsaway.info/tag/ai.html">AI</a><sup>5</sup></div>
            <div class="niu2-sidebar-inter-value niu2-sidebar-tag"><a href="http://spiritsaway.info/tag/converge.html">Converge</a><sup>5</sup></div>
    </div>

    <div id="niu2-sidebar-toc" class="niu2-sidebar" data-status="closed">
        <div class="niu2-sidebar-label">
            <i id="niu2-sidebar-toc-ctrl" class="fa fa-plus"></i>目录
        </div>
        <a href="#content-heading">The Boosting Method</a>
        <ol id="niu2-sidebar-toc-list">
            <li><a href='#2c97b8'>Boosting方法</a></li><li><a href='#e98c41'>boosting简单图解</a></li><li><a href='#085c16'>极简boosting</a></li><li><a href='#3437d4'>adaboost</a></li><li><a href='#ea6f3b'>参考链接</a></li>
            <li><a href="#content-comments">评论</a></li>
        </ol>
    </div>
</div>
    </div>

    <div id="body-footer" class="col-md-6 col-md-offset-3">
<div class="niu2-footer">
    <hr/>
	<p>
		Powered by <a href="https://github.com/getpelican/pelican">Pelican</a>, 
        theme built with <a href="http://getbootstrap.com">Bootstrap3</a> 
		modified by <a href="https://github.com/FinalTheory/pelican-theme">FinalTheory</a>, 
		icons by <a href="http://fortawesome.github.io/Font-Awesome">Font Awesome</a>.
	</p>
	<p>
		COPYRIGHT ©
				2014-2015
		<a class="niu2-footer-link" href="http://spiritsaway.info">Huiliang Huang</a>
    </p>
</div>    </div>
    
    <div id="niu2-pygments" data-theme="github"></div>

    <script type="text/javascript" src="http://spiritsaway.info/theme/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="http://spiritsaway.info/theme/js/niu2.js"></script>
    <script type="text/javascript" src="http://spiritsaway.info/theme/js/bootstrap.min.js"></script>
    <script type="text/javascript">onContentLoaded();</script>
  </body>
</html>